{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning LLMs for machine translation task"
      ],
      "metadata": {
        "id": "r96E4gzeZvFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be finetuning Text-to-Text Transformer (T5) for machine translation task."
      ],
      "metadata": {
        "id": "bpI4Hwczk7n9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## T5 ([Raffel et al.](https://arxiv.org/pdf/1910.10683))\n",
        "\n",
        "T5 uses an encoder-decoder architecture that closely resembles the original transformer.\n",
        "\n",
        "T5's unique feature is its unified text-to-text approach that reformulates all NLP tasks into a consistent format:\n",
        "\n",
        "- Every task is framed as a text-to-text transformation problem\n",
        "- Output is always generated as text, even for classification tasks\n",
        "- Input includes task-specific prefixes\n",
        "\n",
        "For example,\n",
        "\n",
        "Translation: \"translate English to German: Hello!\" → \"Hallo!\"\n",
        "Sentiment analysis: \"st sentence: I had a great time!\" → \"positive\"\n",
        "\n",
        "### Pre-training\n",
        "\n",
        "The model is pre-trained on the [Colossal Clean Crawled Corpus (C4)](https://www.tensorflow.org/datasets/catalog/c4). This has several advantages:\n",
        "\n",
        "- Twice as big as Wikipedia\n",
        "- Cleaned through deduplication and filtering\n",
        "\n",
        "### How is it different from the original transformer?\n",
        "\n",
        "- T5 reformulates all NLP tasks into a text-to-text format, unlike the original transformer which was primarily designed for machine translation\n",
        "- Uses task-specific prefixes (e.g., \"translate:\", \"summarize:\")\n",
        "\n",
        "#### Key differences:\n",
        "\n",
        "- Applies normalization before attention and feed-forward layers instead of after\n",
        "- Uses residual connections after each sub-layer to maintain gradient flow\n",
        "- Dropout is applied throughout the network (e.g., attention weights, feed forward network, skip connection, etc.). Remeber: Dropout is a regularization technique used to prevent overfitting. We randomly deactivating neurons during training with a specified probability\n",
        "- Uses alternating sine and cosine functions for position encoding\n",
        "\n",
        "### Pre-LN Architecture\n",
        "\n",
        "- Places layer normalization inside residual blocks\n",
        "- Enables training without learning rate warm-up\n",
        "- Results in better training stability\n"
      ],
      "metadata": {
        "id": "L9kUjJAYlSBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzN7XFZNwVJf"
      },
      "outputs": [],
      "source": [
        "# transformers: Hugging Face's library for state-of-the-art NLP models\n",
        "# datasets: Library for easily accessing and sharing datasets\n",
        "# evaluate: Framework for evaluating machine learning models\n",
        "# sacrebleu: Library for evaluating machine translation quality using BLEU score\n",
        "\n",
        "!pip install transformers datasets evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and modules\n",
        "\n",
        "# Load datasets from Hugging Face's datasets library\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Import essential components from transformers library:\n",
        "from transformers import (\n",
        "    AutoTokenizer,          # For automatic tokenizer loading based on model name\n",
        "    DataCollatorForSeq2Seq, # Handles batching and padding for sequence-to-sequence tasks\n",
        "    AutoModelForSeq2SeqLM,  # For automatic loading of sequence-to-sequence models\n",
        "    Seq2SeqTrainingArguments, # Contains training configuration\n",
        "    Seq2SeqTrainer,         # Handles the training loop for sequence-to-sequence models\n",
        "    pipeline               # Provides easy-to-use interfaces for various NLP tasks\n",
        ")\n",
        "\n",
        "# Import evaluation tools\n",
        "from evaluate import evaluator\n",
        "import evaluate\n",
        "\n",
        "# Import numerical computing library\n",
        "import numpy as np\n",
        "\n",
        "# Import PyTorch for deep learning operations\n",
        "import torch\n",
        "\n",
        "# Import DatasetDict for managing train/validation/test splits\n",
        "from datasets import DatasetDict"
      ],
      "metadata": {
        "id": "ab9vs0gMcay7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading dataset\n"
      ],
      "metadata": {
        "id": "kXO5VNVLa0AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TED Talks dataset from IWSLT 2013 conference\n",
        "# Parameters:\n",
        "# - \"ted_iwlst2013\": Dataset name (TED talks from IWSLT 2013)\n",
        "# - \"de-en\": Language pair (German to English)\n",
        "# - trust_remote_code=True: Allows execution of remote code for dataset loading\n",
        "dataset = load_dataset(\"ted_iwlst2013\", \"de-en\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "KwoA-OFYwXQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "id": "fyvQyaV8f5ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "DatasetDict({\n",
        "    # Training split containing:\n",
        "    train: Dataset({\n",
        "        # Features in the dataset:\n",
        "        features: [\n",
        "            'id',           # Unique identifier for each example\n",
        "            'translation'   # Contains the parallel text pairs\n",
        "        ],\n",
        "        num_rows: 143836   # Total number of training examples\n",
        "    })\n",
        "})\n",
        "```"
      ],
      "metadata": {
        "id": "kMidYVMXbS9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained tokenizer for the T5-small model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
      ],
      "metadata": {
        "id": "2wNkt-oEcgE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Split the data into train, test and validation sets\n",
        "\n",
        "# Split the first 50000 examples of the training dataset into train and test sets\n",
        "\n",
        "dataset_train_valid_test_split = dataset[\"train\"].select(range(50000)).train_test_split(test_size=0.1)\n",
        "\n",
        "# Split the test set into validation and test sets\n",
        "dataset_test_valid = dataset_train_valid_test_split[\"test\"].select(range(5000)).train_test_split(test_size=0.5)\n",
        "\n",
        "data_dict = DatasetDict({\n",
        "    'train': dataset_train_valid_test_split['train'],  # Training data\n",
        "    'test': dataset_test_valid['test'],                # Test data\n",
        "    'valid': dataset_test_valid['train']               # Validation data\n",
        "})"
      ],
      "metadata": {
        "id": "DiF-cmYKxH5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define source and target languages\n",
        "src_lang = \"en\"                # Source language: English\n",
        "tgt_lang = 'de'                # Target language: German\n",
        "\n",
        "# Create prefix required by T5 model to identify the translation task\n",
        "prefix = \"translate English to German: \"\n",
        "\n",
        "# Define function to preprocess and tokenize the dataset\n",
        "def preprocess(dataset):\n",
        "    # Create input texts by adding prefix to English sentences\n",
        "    inputs = [prefix + data[src_lang] for data in dataset[\"translation\"]]\n",
        "\n",
        "    # Extract German target sentences\n",
        "    targets = [data[tgt_lang] for data in dataset[\"translation\"]]\n",
        "\n",
        "    # Tokenize both inputs and targets\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,                # Source sentences with prefix\n",
        "        text_target=targets,   # Target sentences\n",
        "        max_length=128,        # Maximum sequence length\n",
        "        truncation=True        # Truncate sequences longer than max_length\n",
        "    )\n",
        "    return model_inputs\n",
        "\n",
        "# Apply preprocessing to all splits in the dataset\n",
        "data_dict_tokenized = data_dict.map(preprocess, batched=True)"
      ],
      "metadata": {
        "id": "SSjq1c6zx9qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SacreBLEU evaluation metric\n",
        "# SacreBLEU is a standardized BLEU score implementation for machine translation evaluation\n",
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# BLEU (Bilingual Evaluation Understudy) Score Explanation\n",
        "#\n",
        "# Definition:\n",
        "# - Metric for evaluating machine translation quality\n",
        "# - Scores range from 0 to 100 (higher is better)\n",
        "# - Compares machine translation with human reference(s)\n",
        "#\n",
        "# How BLEU Works:\n",
        "# 1. N-gram Matching:\n",
        "#    - Unigrams: Individual words\n",
        "#    - Bigrams: Pairs of consecutive words\n",
        "#    - Trigrams: Three consecutive words\n",
        "#    - 4-grams: Four consecutive words\n",
        "#\n",
        "# Interpretation:\n",
        "# - 0-15: Poor translation\n",
        "# - 15-30: Understandable but with errors\n",
        "# - 30-50: Good translation\n",
        "# - 50+: High-quality translation\n",
        "# - 100: Perfect match (extremely rare)\n",
        "#\n",
        "# Limitations:\n",
        "# - Doesn't capture meaning preservation\n",
        "# - Sensitive to word order\n",
        "# - May not reflect human judgment perfectly"
      ],
      "metadata": {
        "id": "AbIqi1e2dRAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean predictions and labels for evaluation\n",
        "def clean_texts(preds, labels):\n",
        "    # Remove leading/trailing whitespace from predictions\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "\n",
        "    # Remove whitespace from labels and wrap each in a list\n",
        "    # Labels are wrapped in lists because BLEU expects multiple references\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "id": "WN6hkkMpdyYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute BLEU score for model evaluation\n",
        "def compute_metrics(pred_labels):\n",
        "    # Unpack predictions and labels\n",
        "    preds, labels = pred_labels\n",
        "\n",
        "    # Handle case where predictions are returned as tuple (happens during training)\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    # Decode predictions from token IDs back to text\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace padding tokens (-100) with the pad token ID\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    # Decode labels from token IDs back to text\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Clean and format predictions and labels\n",
        "    decoded_preds, decoded_labels = clean_texts(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    result = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    # Extract just the score from the result\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "nN9tnRgdycbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the T5-small model and move it to GPU (device 0)\n",
        "t5 = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")  # Load pre-trained T5 model\n",
        "t5.to(0)  # Move model to first GPU (device ID 0)\n"
      ],
      "metadata": {
        "id": "ja9MXsmGdgNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a data collator for sequence-to-sequence tasks\n",
        "# DataCollatorForSeq2Seq handles batch preparation and dynamic padding\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,  # The tokenizer used to process text\n",
        "    model=t5             # The T5 model being used\n",
        ")\n",
        "\n",
        "\n",
        "# - Pads sequences within each batch to same length\n",
        "# - Uses maximum length in current batch only\n",
        "# - More memory efficient than global padding"
      ],
      "metadata": {
        "id": "ep0IhOu4yKJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training arguments for fine-tuning the T5 model\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    # Directory to save model checkpoints and logs\n",
        "    output_dir=\"/content/drive/My Drive/machine_translation_t5\",\n",
        "\n",
        "    # Evaluate model after each epoch\n",
        "    evaluation_strategy=\"epoch\",\n",
        "\n",
        "    # Learning rate for optimization\n",
        "    learning_rate=2e-5,\n",
        "\n",
        "    # Batch sizes for training and evaluation\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "\n",
        "    # L2 regularization factor (This penalty encourages the model to use smaller weights during training)\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # Keep only the last 3 checkpoints\n",
        "    save_total_limit=3,\n",
        "\n",
        "    # Number of training epochs\n",
        "    num_train_epochs=2,\n",
        "\n",
        "    # Enable text generation during evaluation\n",
        "    predict_with_generate=True,\n",
        "\n",
        "    # Enable mixed precision training (faster training, less memory)\n",
        "    fp16=True,\n",
        "\n",
        "    # Disable external reporting\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "ahIB27Lreznd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Sequence-to-Sequence Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=t5,                                    # Pre-trained T5 model\n",
        "    args=training_args,                          # Training configuration\n",
        "    train_dataset=data_dict_tokenized[\"train\"],  # Training data\n",
        "    eval_dataset=data_dict_tokenized[\"valid\"],   # Validation data\n",
        "    tokenizer=tokenizer,                         # Tokenizer for text processing\n",
        "    data_collator=data_collator,                 # Handles batch preparation\n",
        "    compute_metrics=compute_metrics,             # Evaluation metric function\n",
        ")"
      ],
      "metadata": {
        "id": "pn52FNv8Hd5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the pre-trained model on test set before fine-tuning\n",
        "prefinetuned_results = trainer.evaluate(\n",
        "    eval_dataset=data_dict_tokenized[\"test\"]  # Use test split for evaluation\n",
        ")\n"
      ],
      "metadata": {
        "id": "VyW1Iu4lyfxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the BLEU score achieved on test set before fine-tuning\n",
        "print(\"Test set bleu score before finetuning: \", prefinetuned_results[\"eval_bleu\"])"
      ],
      "metadata": {
        "id": "OjqFALI55d6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model with a conversational example sentence\n",
        "test_text = \"translate English to German: I am a student of English language and Linguistics. I really like working with LLMs.\"\n",
        "\n",
        "# Convert input text to token IDs and move to GPU\n",
        "inputs_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids.to(0)\n",
        "\n",
        "# Generate translation with specified parameters\n",
        "outputs = t5.generate(\n",
        "    inputs_ids,\n",
        "    max_new_tokens=40,    # Maximum length of generated translation\n",
        "    do_sample=True,       # Enable sampling for more natural output\n",
        "    top_k=30,            # Consider top 30 tokens for sampling\n",
        "    top_p=0.95,          # Nucleus sampling threshold\n",
        ")\n",
        "\n",
        "# Decode and print the translation\n",
        "print(\"Translation of example sentence: \", tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "XnQEGCIeQIfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finetune the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "95JQyOZOzHSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test set after fine-tuning\n",
        "postfinetuned_results = trainer.evaluate(\n",
        "    eval_dataset=data_dict_tokenized[\"test\"]  # Use test split for evaluation\n",
        ")"
      ],
      "metadata": {
        "id": "uwN8l8wPhDGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test set bleu score after finetuning: \", postfinetuned_results[\"eval_bleu\"])\n"
      ],
      "metadata": {
        "id": "aKsOf_y5eDb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Try translating the example sentence again to see if the translation improved\n",
        "test_text = \"translate English to German: I am a student of English language and Linguistics. I really like working with LLMs.\"\n",
        "inputs_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids.to(0)\n",
        "outputs = t5.generate(inputs_ids, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
        "print(\"Translation of example sentence: \", tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "WCR8XkIC27G4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}